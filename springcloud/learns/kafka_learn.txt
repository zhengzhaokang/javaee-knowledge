Kafka是如何保证消息不丢失?
需要从三个层面去解决这个问题:
1.生产者发送消息到Brocker丢失
设置异步发送，发送失败使用回调进行记录或重发失败重试，参数配置，可以设置重试次数
2.消息在Brocker中存储丢失
发送确认acks，选择all，让所有的副本都参与保存数据后确认
3.消费者从Brocker接收消息丢失
关闭自动提交偏移量，开启手动提交偏移量
提交方式，最好是同步+异步提交

1. 生产者配置
acks=all：要求所有副本确认写入后，生产者才认为消息发送成功。
retries=Integer.MAX_VALUE：无限重试，避免网络波动导致消息丢失。
max.in.flight.requests.per.connection=1：确保消息按顺序发送，避免重试导致乱序。
2. Broker 配置
replication.factor=3：设置每个分区的副本数为 3，确保高可用。
min.insync.replicas=2：要求至少 2 个副本处于同步状态，才能接受写入。
unclean.leader.election.enable=false：禁止从非同步副本中选举 Leader，避免数据丢失。
3. 消费者配置
手动提交偏移量：确保消息处理完成后再提交偏移量，避免消费者崩溃导致消息丢失。
enable.auto.commit=false：关闭自动提交偏移量。

Kafka中消息的重复消费问题如何解决的?
1.关闭自动提交偏移量，开启手动提交偏移量
2.提交方式，最好是同步+异步提交
3.幂等方案


Kafka是如何保证消费的顺序性?
问题原因:
-个topic的数据可能存储在不同的分区中，每个分区都有一个按照顺序的存储的偏移量，
如果消费者关联了多个分区不能保证顺序性
解决方案:
1.发送消息时指定分区号
2.发送消息时按照相同的业务设置相同的key.


Kafka的高可用机制有了解过嘛?
可以从两个层面回答，第一个是集群，第二个是复制机制
集群:
一个kafka集群由多个broker实例组成，即使某一台宕机，也不耽误其他broker继续对外提供服务
复制机制:
一个topic有多个分区，每个分区有多个副本，有一个eader，其余的是follower，
副本存储在不同的broker中所有的分区副本的内容是都是相同的，
如果leader发生故障时，会自动将其中一个follower提升为leader，保证了系统的容错性、高可用性

解释一下复制机制中的ISR?
ISR(in-syncreplica)需要同步复制保存的follower分区副本分为了两类，一个是ISR，与leader副本同步保存数据，
另外一个普通的副本，是异步同步数据，当leader挂掉之后，会优先从ISR副本列表中选取一个作为leader


Kafka数据清理机制了解过嘛
1.Kafka存储结构
Kafka中topic的数据存储在分区上，分区如果文件过大会分段存储segment
每个分段都在磁盘上以索引(xxxx.index)和日志文件(xxxx.log)的形式存储，
分段的好处是:第一能够减少单个文件内容的大小，查找数据方便，第二方便kafka进行日志清理日志的
2.清理策略有两个!
根据消息的保留时间，当消息保存的时间超过了指定的时间，就会触发清理，默认是168小时(7天)
根据topic存储的数据大小，当topic所占的日志文件大小大于一定的阈值，则开始删除最久的消息。(默认关闭)


Kafka中实现高性能的设计有了解过嘛
1.消息分区:不受单台服务器的限制，可以不受限的处理更多的数据
2.顺序读写:1磁盘顺序读写，提升读写效率.
3.页缓存:按把磁盘中的数据缓存到内存中，把对磁盘的访问变为对内存的访问
4.零拷贝:减少上下文切换及数据拷贝
5.消息压缩:减少磁盘I0和网络I0
6.分批发送:将消息打包批量发送，减少网络开销